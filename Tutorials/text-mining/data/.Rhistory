library(tidyverse)
library(tidytext)
#Stemming packages
library(SnowballC)
wd = "C:\\Users\\bryan\\source\\repos\\msis5193-pds1-master\\text-mining\\data"
setwd(wd)
temptable = paste(wd, "\\tweets.csv", sep = "")
tweets_data = read.csv(temptable, header = TRUE)
airline_tweets = select(tweets_data, text, airline_sentiment)
tidy_dataset = unnest_tokens(airline_tweets, word, text)
#===============================
# Alternative using pipe symbol
airline_tweets = tweets_data %>%
select(text, airline_sentiment)
tidy_dataset = airline_tweets %>%
unnest_tokens(word, text)
# Count the most popular words
tidy_dataset %>%
count(word) %>%
arrange(desc(n))
#=====================================
# Remove stop words from the data by
# using the dataset stop_words found
# in the tidytext package
#=====================================
data("stop_words")
# Alternative using pipe symbol
tidy_dataset2 = tidy_dataset %>%
anti_join(stop_words)
tidy_dataset2 %>%
count(word) %>%
arrange(desc(n))
#==============================================
# Remove the numerical values from the column
# word. tidytext automatically makes all
# words lower case, no conversion necessary.
#==============================================
patterndigits = '\\b[0-9]+\\b'
# Alternative
tidy_dataset2$word = tidy_dataset2$word %>%
str_replace_all(patterndigits, '')
# Alternative
tidy_dataset2$word = tidy_dataset2$word %>%
str_replace_all('[:space:]', '')
tidy_dataset3 = tidy_dataset2 %>%
filter(!(word == ''))
#==============================
# Plot the the words with a
# proportion greater than 0.5
#==============================
frequency = tidy_dataset3 %>%
count(word) %>%
arrange(desc(n)) %>%
mutate(proportion = (n / sum(n)*100)) %>%
filter(proportion >= 0.5)
library(scales)
ggplot(frequency, aes(x = proportion, y = word)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme(legend.position="none") +
labs(y = 'Word', x = 'Proportion')
#=======================
# Remove airline names
#=======================
list = c("southwestair","jetblue","united","virginamerica",
"americanair","usairways","http","t.co")
tidy_dataset3 = tidy_dataset3 %>%
filter(!(word %in% list))
tidy_dataset3
tidy_dataset3 %>%
count(word) %>%
arrange(desc(n))
#=======================
# Remove airline names
#=======================
list_remove = c("southwestair","jetblue","united","virginamerica",
"americanair","usairways","http","t.co")
# Alternative
tidy_dataset3 = tidy_dataset3 %>%
filter(!(word %in% list))
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = mutate_at(tidy_dataset3, "word", funs(wordStem((.), language="en")))
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = mutate_at(tidy_dataset3, "word", list(wordStem((.), language="en")))
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = mutate_at(tidy_dataset3, "word", wordStem())
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = mutate_at(tidy_dataset3, "word", wordStem((.), language="en"))
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = mutate_at(tidy_dataset3, "word", wordStem(., language="en"))
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = mutate_at(tidy_dataset3, "word", wordStem(tidy_dataset3$word, language="en"))
wordStem(tidy_dataset3$word, language="en")
# Alternative
tidy_dataset4 = tidy_dataset3 %>%
mutate_at("word", funs(wordStem((.), language="en")))
tidy_dataset4 = mutate_at(tidy_dataset3, "word", funs(wordStem(tidy_dataset3, language="en")))
tidy_dataset4 = mutate_at(tidy_dataset3$word, funs(wordStem(tidy_dataset3, language="en")))
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = mutate_at(tidy_dataset3, "word", funs(wordStem(tidy_dataset3, language="en")))
# Alternative
tidy_dataset4 = tidy_dataset3 %>%
mutate_at("word", funs(wordStem((.), language="en")))
tidy_dataset4
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = wordStem(tidy_dataset3$word, language="en")
tidy_dataset4
head(tidy_dataset4)
# Alternative
tidy_dataset4 = tidy_dataset3 %>%
mutate_at("word", funs(wordStem((.), language="en")))
tidy_dataset4
#=======================================
# Using the SnowballC package, run the
# function wordStem() on the data to
# apply stemming to the data
#=======================================
tidy_dataset4 = mutate_at(tidy_dataset3, "word", funs(wordStem((.), language="en")))
counts5 = count(tidy_dataset4, word)
arrange(counts5, desc(n))
frequency2 = tidy_dataset4 %>%
count(word) %>%
arrange(desc(n)) %>%
mutate(proportion = (n / sum(n)*100)) %>%
filter(proportion >= 0.5)
ggplot(frequency2, aes(x = proportion, y = word)) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme(legend.position="none") +
labs(y = 'Word', x = 'Proportion')
#===================================
# Construct a document-term matrix
# for further analysis
#===================================
counts6 = count(tidy_dataset4, word)
tidy_tdm = cast_dtm(counts6, airline_sentiment, word, n)
tidy_dataset4
tidy_tdm = cast_dtm(counts5, airline_sentiment, word, n)
counts5
# Alternative
tidy_tdm = tidy_dataset4 %>%
count(airline_sentiment, word) %>%
cast_dtm(airline_sentiment, word, n)
tidy_tdm
#===================================
# Construct a document-term matrix
# for further analysis
#===================================
tidy_tdm = count(tidy_dataset4, airline_sentiment, word) %>%
cast_dtm(airline_sentiment, word, n)
#===================================
# Construct a document-term matrix
# for further analysis
#===================================
tidy_tdm = cast_dtm(tidy_dataset4, airline_sentiment, word, counts5$n)
counts5
#===================================
# Construct a document-term matrix
# for further analysis
#===================================
tidy_tdm = cast_dtm(tidy_dataset4, airline_sentiment, word, counts5$n)
#===================================
# Construct a document-term matrix
# for further analysis
#===================================
tidy_tdm = cast_dtm(tidy_dataset4$airline_sentiment, tidy_dataset4$word, counts5$n)
tidy_dataset4$airline_sentiment
tidy_dataset4$word
counts5$n
